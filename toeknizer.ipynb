{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:36:45.989013100Z",
     "start_time": "2025-01-10T04:36:45.978960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tokenizers import decoders, models, pre_tokenizers, trainers, Tokenizer\n",
    "import os \n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:42:22.054996Z",
     "start_time": "2025-01-10T04:42:22.002926600Z"
    }
   },
   "id": "ad185775730521f9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path = './tokenizer_train.jsonl'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:17.861863200Z",
     "start_time": "2025-01-10T04:45:17.843301400Z"
    }
   },
   "id": "7b38314b0709350a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "def read_data(path):\n",
    "  with open(path, 'r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "      data = json.loads(line)\n",
    "      yield data['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:18.898476200Z",
     "start_time": "2025-01-10T04:45:18.873681100Z"
    }
   },
   "id": "b3621b3bd059dd21"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())\n",
    "# ???\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:20.206729600Z",
     "start_time": "2025-01-10T04:45:20.179129100Z"
    }
   },
   "id": "b17e3924024bbe8b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "special_tokens = ['<pad>','<unk>','<s>','</s>']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:21.414640600Z",
     "start_time": "2025-01-10T04:45:21.387558600Z"
    }
   },
   "id": "86a1c60644433539"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size = 6400,\n",
    "    special_tokens = special_tokens,\n",
    "    show_progress = True,\n",
    "    initial_alphabet = pre_tokenizers.ByteLevel.alphabet()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:22.359463100Z",
     "start_time": "2025-01-10T04:45:22.331813Z"
    }
   },
   "id": "817f1229ba6db293"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "texts = read_data(path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:45:24.380084200Z",
     "start_time": "2025-01-10T04:45:24.370514700Z"
    }
   },
   "id": "d07d959f3b8d70e6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 设置解码器 \n",
    "tokenizer.train_from_iterator(texts, trainer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:57:56.033363300Z",
     "start_time": "2025-01-10T04:45:25.531948600Z"
    }
   },
   "id": "b9ac1d888d1e6d0c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('finished')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T04:57:56.155347700Z",
     "start_time": "2025-01-10T04:57:56.020578500Z"
    }
   },
   "id": "15f2091341e385b7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.ByteLevel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:10:26.746616500Z",
     "start_time": "2025-01-10T05:10:26.726590200Z"
    }
   },
   "id": "446884ec6803342d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "tokenizer.save(\"tokenizer.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:10:28.112630700Z",
     "start_time": "2025-01-10T05:10:28.083489400Z"
    }
   },
   "id": "5485d8b1805f71"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "tokenizer_dir = \"./tokenizer\"\n",
    "os.makedirs(tokenizer_dir, exist_ok=True)\n",
    "tokenizer.save(os.path.join(tokenizer_dir, \"tokenizer.json\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:23:50.599377700Z",
     "start_time": "2025-01-10T05:23:50.567413Z"
    }
   },
   "id": "d0e3611a89a952a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['./tokenizer\\\\vocab.json', './tokenizer\\\\merges.txt']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model.save(tokenizer_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:24:05.774876400Z",
     "start_time": "2025-01-10T05:24:05.717881500Z"
    }
   },
   "id": "75ceff8a5cb4f710"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:14:15.253601500Z",
     "start_time": "2025-01-10T05:14:10.772901400Z"
    }
   },
   "id": "af177d3b61d924c8"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "config = {\n",
    "        # 序列开始是否添加 begin and end token\n",
    "        \"add_bos_token\": False,\n",
    "        \"add_eos_token\": False,\n",
    "        \"add_prefix_space\": True,\n",
    "        \"added_tokens_decoder\": {\n",
    "            \"0\": {\n",
    "                \"content\": \"<unk>\",\n",
    "                \"lstrip\": False,\n",
    "                \"normalized\": False,\n",
    "                \"rstrip\": False,\n",
    "                \"single_word\": False,\n",
    "                \"special\": True\n",
    "            },\n",
    "            \"1\": {\n",
    "                \"content\": \"<s>\",\n",
    "                \"lstrip\": False,\n",
    "                \"normalized\": False,\n",
    "                \"rstrip\": False,\n",
    "                \"single_word\": False,\n",
    "                \"special\": True\n",
    "            },\n",
    "            \"2\": {\n",
    "                \"content\": \"</s>\",\n",
    "                \"lstrip\": False,\n",
    "                \"normalized\": False,\n",
    "                \"rstrip\": False,\n",
    "                \"single_word\": False,\n",
    "                \"special\": True\n",
    "            }\n",
    "        },\n",
    "        \"additional_special_tokens\": [],\n",
    "        # 设置<s> 提示其为begin of sequence 令tokenizer可识别\n",
    "        \"bos_token\": \"<s>\",\n",
    "        \"clean_up_tokenization_spaces\": False,\n",
    "        \"eos_token\": \"</s>\",\n",
    "        \"legacy\": True,\n",
    "        \"model_max_length\": 100000,\n",
    "        \"pad_token\": None,\n",
    "        \"sp_model_kwargs\": {},\n",
    "        \"spaces_between_special_tokens\": False,\n",
    "        \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"use_default_system_prompt\": False,\n",
    "        \"chat_template\": \"{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<s>user\\\\n' + content + '</s>\\\\n<s>assistant\\\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '</s>' + '\\\\n' }}{% endif %}{% endfor %}\"\n",
    "    }\n",
    "\n",
    "# 保存配置文件\n",
    "with open(os.path.join(tokenizer_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as config_file:\n",
    "    json.dump(config, config_file, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:25:19.534755Z",
     "start_time": "2025-01-10T05:25:19.505584300Z"
    }
   },
   "id": "798d76eac8ef61eb"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "[804, 588]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")\n",
    "tokenizer.encode(\"您好\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:26:53.963270600Z",
     "start_time": "2025-01-10T05:26:53.931663Z"
    }
   },
   "id": "a27f30fc68524183"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 中文词表并不是一一对应关系，如 禹是 [1458, 121] 博是[5604]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd57a28f2150bbc6"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[398, 5516, 2467, 5604, 1458, 121]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"我叫张博禹\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:28:29.184959800Z",
     "start_time": "2025-01-10T05:28:29.163671600Z"
    }
   },
   "id": "f0857e9247e48eed"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'禹'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1458,121])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T05:29:10.352096300Z",
     "start_time": "2025-01-10T05:29:10.330986100Z"
    }
   },
   "id": "79758c0dcf197665"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer1.encode(\"哈喽\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c7b8405e4866b8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c48caa697db455a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
